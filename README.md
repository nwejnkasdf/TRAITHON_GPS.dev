# TRAITHON_GPS.dev
Trustworthy AI competition portfolio

## 1. 권효중
## 2. 김준호
## 3. 윤현정
## 4. Woonjung Lee

### 4.1. Summary:
Working as a Data Scientist, conducted explainability-driven analysis and section-level bias evaluation for a clickbait detection system, and performed stress testing to identify and validate model failure modes under realistic conditions.
Also led report authoring and contributed to evidence mapping and presentation material preparation.

### 4.2. Detail:
- Designed and implemented Integrated Gradients–based XAI analysis code, and empirically validated model decision rationales through controlled experiments.
- Formulated section-level bias hypotheses based on label and subcategory distributions, and built a data proportion analysis pipeline from scratch to perform quantitative bias validation.
- Designed stress-test scenarios using disaster news datasets, modeling extreme cases where sensational lexicon is used in legitimate public-interest contexts, and verified model failure modes in which such cases are misclassified as clickbait.
- Led overall report and deliverable authoring, ensuring coherence and consistency across project outputs.
- Participated in systematic evidence mapping across experiments and analyses.
- Contributed to the development of presentation materials.

## 5. HyunJin Choi

### 5.1. Summary: 
Working as Data Scientist, performed statistical bias and robustness analysis for a clickbait detection system, including dependency tests, stress testing, and fairness monitoring design.

### 5.2. Detail:
- Defined and analyzed data bias issues in a clickbait article detection AI competition, statistically validating whether section-wise performance gaps stem from genuine section effects or structural confounding.
- Applied χ² tests and CMH conditional independence tests to disentangle section effects from processing-pattern confounders, and developed an effect-size – driven interpretation framework.
- Designed and conducted a section-swapping stress test to evaluate the impact of section–label dependency on model performance, confirming robustness to structural bias within the current data scope.
- Extended data and model analysis into an SLI/SLO-based fairness monitoring and risk management framework, proposing exposure-aware section-wise bias detection metrics and operational thresholds.
